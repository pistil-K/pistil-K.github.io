<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-数据挖掘" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/03/09/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" class="article-date">
  <time class="dt-published" datetime="2025-03-09T08:25:06.000Z" itemprop="datePublished">2025-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/03/09/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、绪论"><a href="#一、绪论" class="headerlink" title="一、绪论"></a>一、绪论</h1><p>1.什么是数据挖掘 </p>
<p>在一个大型的数据库里面可以自动发现有用信息，也可以预测未来的结果</p>
<p>注意区分于信息检索，这个重点在索引</p>
<p>KDD(knowledge discovery in database): 将未加工数据转化为有用信息<br><img src="/../images/KDD.png" alt="图片1"></p>
<ul>
<li>preprocessing: 将未加工输入数据转换成适合分析的形式。步骤包括<ul>
<li>融合多个来自数据源的数据</li>
<li>清洗数据以消除噪声和重复观测值</li>
<li>选择与当前数据挖掘任务相关的记录和特征</li>
</ul>
</li>
<li>closing thw loop: 数据挖掘结果集成倒决策支持系统的过程</li>
</ul>
<p>1.2 数据挖掘要解决的问题</p>
<p>1.4 数据挖掘的任务</p>
<p>一般分为两大类</p>
<ul>
<li><p>预测任务</p>
<ul>
<li>预测建模：任务就是分类和回归</li>
</ul>
</li>
<li><p>描述任务：导出概况数据中潜在联系的模式(相关、趋势、聚类、轨迹和异常)</p>
<ul>
<li>聚类分析<ul>
<li>紧密相关的观测值组群</li>
</ul>
</li>
<li>关联分析<ul>
<li>描述数据中强关联模型，一般是蕴含规则或特征子集的形式。</li>
</ul>
</li>
<li>异常检测</li>
</ul>
</li>
</ul>
<p>e.g.这里说监视病人心率异常变化&#x2F;地震活动的地震波都是数据挖掘任务，因为之后还要做大量分析(这里不太认同，它明明只说监视，又没说分析)；而提取声波频率不是数据挖掘任务，因为它只是特征提取</p>
<h1 id="第二章-数据"><a href="#第二章-数据" class="headerlink" title="第二章 数据"></a>第二章 数据</h1><h2 id="2-1-数据类型"><a href="#2-1-数据类型" class="headerlink" title="2.1 数据类型"></a>2.1 数据类型</h2><h3 id="2-1-1-属性与度量"><a href="#2-1-1-属性与度量" class="headerlink" title="2.1.1 属性与度量"></a>2.1.1 属性与度量</h3><ol>
<li><p>属性包含符号属性(具有少量的可能的值)和数值属性(可以取无穷个值)</p>
</li>
<li><p>测量标度：将数值或符号值与对象的属性相关联的规则（函数）</p>
</li>
</ol>
<h3 id="2-1-2数据集的类型"><a href="#2-1-2数据集的类型" class="headerlink" title="2.1.2数据集的类型"></a>2.1.2数据集的类型</h3><p>一般将数据集类型分为三组：记录数据、基于图形的数据和有序数据</p>
<ol>
<li>数据集的一般特性</li>
</ol>
<ul>
<li>维度：数据集的维度是数据集中对象具有的属性数目。分析高维数据有时会陷入维灾难。因此数据预处理一个重要动机就是减少维度，称为维归约</li>
<li>稀疏性：数据集，如具有非对称特征的数据集，一个对象的大部分属性上的值都为0。实际上，稀疏性是一个优点，只有非0值才需要存储和处理。着将节省大量的计算时间和存储空间。此外，有些数据挖掘算法仅适合处理稀疏数据。</li>
<li>分辨率：常常可以在不同分辨率下得到数据，并且在不同分辨率下数据的性质不同。数据的模式也依赖于分辨率</li>
</ul>
<ol start="2">
<li>记录数据</li>
</ol>
<p>数据集是记录（数据对象）（一行行）的汇总，每个记录包含固定的数据字段（属性）集。每个记录（对象）有相同的属性集。记录数据通常放在平展文件或关系数据库里。</p>
<p>不同类型的记录数据：</p>
<p><img src="/../images/type_of_document.png" alt="image-20250309212054888"></p>
<ul>
<li><p>记录数据</p>
<ul>
<li>每一行独立的、完整的数据条目</li>
</ul>
</li>
<li><p>事务数据（购物篮数据）</p>
<ul>
<li>某一特定交易或者活动的数据</li>
</ul>
</li>
<li><p>数据矩阵（模式矩阵）</p>
<ul>
<li>通过行和列的形式展示数据，行代表个体，列代表特征或变量</li>
</ul>
</li>
<li><p>稀疏数据矩阵（文档-词矩阵）</p>
</li>
</ul>
<ol start="3">
<li>基于图像的数据<ul>
<li>图形捕获数据对象之间的联系</li>
<li>数据对象本身用图形表示：数据有结构（有子对象），经常用图形表示。e.g.苯；可以查找频繁出现的子结构。</li>
</ul>
</li>
<li>有序数据<ul>
<li>时序数据（时间数据）：每条记录多记了一条和时间相关的数据</li>
<li>序列数据：和时序序列区别只是没有时间戳，它考虑项的位置</li>
<li>时间序列数据：特殊时序数据，一段时间的测量序列，性质：拥有时间自相关，如果测量时间很近，测量的值通常相似。e.g. 某个地区从1982倒1994年的月平均气温的时间序列</li>
<li>空间数据：空间自相关性，物理上靠近的对象趋向于在其他方面也相似</li>
</ul>
</li>
<li>处理非记录数据<ul>
<li>大部分数据挖掘算法都是为记录数据及其变体设计，通过从数据对象中提取特征，并使用这些特征创建对应于每个对象的记录，但是也可以记录非记录数据（图和有序数据）</li>
<li>比如：每个化合物都可以用一个具有二元属性的记录表示，判断化合物是否包含子结构。实际上是事务数据集，事务时化合物，项是子结构</li>
</ul>
</li>
</ol>
<h2 id="2-2-数据质量"><a href="#2-2-数据质量" class="headerlink" title="2.2 数据质量"></a>2.2 数据质量</h2><p>对于数据质量，数据挖掘着手与两个方面：（1）数据质量问题的检查和纠正（数据清理）；（2）使用可以容忍低质量数据的算法</p>
<h3 id="2-2-1-测量和数据收集问题"><a href="#2-2-1-测量和数据收集问题" class="headerlink" title="2.2.1 测量和数据收集问题"></a>2.2.1 测量和数据收集问题</h3><ol>
<li>测量误差和数据收集误差<ul>
<li>测量误差：测量过程中导致的问题</li>
<li>数据收集误差：遗漏数据对象或属性值，或不当地包含其他数据对象等错误</li>
<li>上面两种错误可能是系统的也可能是随机的</li>
</ul>
</li>
<li>噪声和伪影<ul>
<li>噪声是测量误差的随机部分。很多数据挖掘算法都关注设计鲁棒算法，即在噪声干扰下也能产生可以接受的结果</li>
</ul>
</li>
<li>精度、偏倚和精确率<ul>
<li>精度：多次测量结果是否接近，结果的一致性</li>
<li>偏倚：结果的准确性，关注的是测量是否存在<strong>系统性误差</strong>，即结果是否始终以某种固定的方式偏离真实值</li>
</ul>
</li>
<li>离群点</li>
<li>遗漏值<ul>
<li>针对遗漏值的策略<ul>
<li>删除数据对象或属性</li>
<li>估计遗漏值</li>
<li>在分析时忽略遗漏值：使用没有遗漏值的属性聚类</li>
</ul>
</li>
</ul>
</li>
<li>不一致的值</li>
<li>重复数据</li>
</ol>
<h3 id="2-2-2-关于应用的问题"><a href="#2-2-2-关于应用的问题" class="headerlink" title="2.2.2 关于应用的问题"></a>2.2.2 关于应用的问题</h3><ul>
<li>时效性</li>
<li>相关性<ul>
<li>抽样偏倚</li>
</ul>
</li>
<li>有关数据的知识：数据集文档应该给出属性强相关（高度冗余，可以留其一）；遗漏值表示；数据精度；特征的类型（标称的、序数的、区间的、比率的）、测量的刻度（如长度用米还是英尺）和数据的来源</li>
</ul>
<h2 id="2-3-数据预处理"><a href="#2-3-数据预处理" class="headerlink" title="2.3 数据预处理"></a>2.3 数据预处理</h2><ol>
<li><p>聚类</p>
<ul>
<li>聚类动机<ul>
<li>数据归约：较少的内存和处理时间，可以使用开销更大的数据挖掘算法</li>
</ul>
</li>
<li>聚类的缺点<ul>
<li>可能丢失有趣的细节</li>
</ul>
</li>
</ul>
</li>
<li><p>抽样</p>
<ul>
<li><p>统计学使用抽样是因为得到感兴趣的整个数据集的费用太高、太浪费时间</p>
</li>
<li><p>数据挖掘使用抽样是因为处理所有数据费用太高，太浪费时间</p>
<p>（1）抽样方法</p>
<ul>
<li>简单随机抽样<ul>
<li>无放回抽样</li>
<li>有放回抽样（分析简单）</li>
</ul>
</li>
<li>分层抽样<ul>
<li>变形：从每一组抽取的对象数量正比于该组的大小</li>
</ul>
</li>
</ul>
<p>（2）渐近抽样</p>
<ul>
<li>合适的样本容量很难确定，因此使用自适应或渐近抽样</li>
<li>从小样本开始，逐渐增加容量知道得到足够大的样本，最后要评估样本容量是否足够大</li>
</ul>
</li>
</ul>
</li>
<li><p>维规约</p>
<ul>
<li>好处<ul>
<li>维归约可以删除不相关的特征并降低噪声，避免维灾难</li>
<li>可以使模型更容易理解</li>
<li>维规约更容易让数据可视化</li>
</ul>
</li>
<li>做法<ul>
<li>创建新属性将旧属性合并。通过选择旧属性的子集得到新属性，这种维规约称为特征子集选择或者特征选择</li>
</ul>
</li>
<li>维灾难<ul>
<li>维度增加，数据所占空间越来越稀疏。分类和聚类效果都下降</li>
<li>维规约的线性代数技术<ul>
<li>对于连续数据，主成分分析（PCA）：找出新的属性（主成分），这些属性是原属性的线性组合，新属性之间是相互正交的，捕获数据最大变差（尽可能全面地获取数据中所包含的差异、变化或波动信息）</li>
<li>奇异值分解（SVD）：<ul>
<li>用途：降维算法的特征分解，推荐系统</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>特征子集选择</p>
<ul>
<li>去掉冗余和不相关特征</li>
<li>三种标注的特征选择方法<ul>
<li>嵌入（与具体的算法有关）</li>
<li>过滤：在数据挖掘算法运行前进行特征选择</li>
<li>包装：使用理想方法</li>
</ul>
</li>
</ul>
</li>
<li><p>特征创建</p>
<p>三种创建新属性性的方法</p>
<ul>
<li>特征提取</li>
<li>映射数据到新的空间：对于时间序列的信息，使用傅里叶变化转化为频率；除了傅里叶变化还有小波变换</li>
<li>特征构造</li>
</ul>
</li>
<li><p>离散化和二元化</p>
</li>
</ol>
<h2 id="2-4-相似性和相异性的度量"><a href="#2-4-相似性和相异性的度量" class="headerlink" title="2.4 相似性和相异性的度量"></a>2.4 相似性和相异性的度量</h2><p>一旦计算出相似性或相异性，就不需要原始数据，可以看做将数据变换到相似性（相异性）空间，之后分析</p>
<p>我们使用邻近度（proximity）来表示相似性或相异性</p>
<ul>
<li>时间序列类似的稠密数据或二维点<ul>
<li>相关</li>
<li>欧几里得距离度量</li>
</ul>
</li>
<li>文档的稀疏数据<ul>
<li>Jaccard</li>
<li>余弦相似性度量</li>
</ul>
</li>
</ul>
<h3 id="2-4-1-基础"><a href="#2-4-1-基础" class="headerlink" title="2.4.1.基础"></a>2.4.1.基础</h3><ol>
<li>定义</li>
</ol>
<ul>
<li>相似度：非负数，范围(0,1)</li>
<li>相异度：可以在[0,1]，也可以在0到正无穷</li>
</ul>
<ol start="2">
<li>变换</li>
</ol>
<ul>
<li>一般邻近度度量范围是[0,1]<ul>
<li>有限值域转化公式: s’&#x3D;(s-min_s)&#x2F;(max_s-min_s)</li>
<li>[0,$\infty$]，使用非线性变换，在新的尺度上，值之间不再具有相同的联系，使用d’&#x3D;d&#x2F;(1+d)</li>
</ul>
</li>
<li>变化相似度为相异度：使用d&#x3D;1-s; 加负号<ul>
<li>一般负变换不必局限于[0,1]，如果希望的话可以使用s&#x3D;1&#x2F;(d+1),$s&#x3D;e^{-4}$,s&#x3D;1-(d-min_d)&#x2F;(max_d-min_d)</li>
</ul>
</li>
</ul>
<h3 id="2-4-2-简单属性之间的相似度和相异度"><a href="#2-4-2-简单属性之间的相似度和相异度" class="headerlink" title="2.4.2 简单属性之间的相似度和相异度"></a>2.4.2 简单属性之间的相似度和相异度</h3><p>标称属性：只是用来区分不同对象的类别，而不涉及任何量化或顺序关系</p>
<p><img src="/../../../Pictures/image-20250310201951265.png" alt="image-20250310201951265"></p>
<h3 id="2-4-3-数据对象之间的相异度"><a href="#2-4-3-数据对象之间的相异度" class="headerlink" title="2.4.3 数据对象之间的相异度"></a>2.4.3 数据对象之间的相异度</h3><ul>
<li><p>欧几里得距离：<img src="../../../Pictures/image-20250310202241474.png" alt="image-20250310202241474" style="zoom:45%;" /></p>
<ul>
<li><p>推广：闵可夫斯基距离：<img src="../../../Pictures/image-20250310202348999.png" alt="image-20250310202348999" style="zoom:40%;" /></p>
<ul>
<li><p>r&#x3D;1: 城市街区（曼哈顿、出租车、L1范数）距离</p>
</li>
<li><p>r&#x3D;2:欧几里得距离(L2范数)</p>
<ul>
<li><p>非负性</p>
</li>
<li><p>对称性</p>
</li>
<li><p>三角不等式</p>
<p>满足上面三个性质的测度是度量(metric)</p>
</li>
</ul>
</li>
<li><p>r&#x3D;$\infty$，上确界距离，对象属性之间的最大距离：<img src="../../../Pictures/image-20250310202705814.png" alt="image-20250310202705814" style="zoom:40%;" /></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-4-4-数据对象之间的相似度"><a href="#2-4-4-数据对象之间的相似度" class="headerlink" title="2.4.4 数据对象之间的相似度"></a>2.4.4 数据对象之间的相似度</h3><h3 id="2-4-5-邻近性度量的例子"><a href="#2-4-5-邻近性度量的例子" class="headerlink" title="2.4.5 邻近性度量的例子"></a>2.4.5 邻近性度量的例子</h3><ol>
<li><p>二元数据的相似性度量</p>
<p>相似系数：两个仅包含二元属性的对象之间的相似性度量，取值于（0，1）</p>
<ul>
<li><p>简单匹配系数：常用相似性系数</p>
<p>SMC&#x3D;值匹配的属性个数&#x2F;属性个数&#x3D;$(f_{11}+f_{10})&#x2F;f_{01}+f_{10}+f_{11}+f_{00}$</p>
<p>即：SMC是在包含非题测验发现回答问题相似的学生</p>
</li>
<li><p>Jaccard系数：处理非对称的二元属性的对象：J&#x3D;匹配的个数&#x2F;不涉及0-0匹配的属性个数&#x3D;$f_{11}&#x2F;(f_{01}+f_{10}+f_{11})$</p>
</li>
</ul>
</li>
<li><p>余弦相似度</p>
<img src="../../../Pictures/image-20250310211511193.png" alt="image-20250310211511193" style="zoom:40%;" />

<ul>
<li>余弦相似度不考虑两个数据对象的量值，但是当量值最重要时，欧几里得距离可能是更好的选择</li>
</ul>
</li>
<li><p>广义Jaccard系数</p>
<ul>
<li>广义Jaccard系数(Tanimoto系数)可以用于文档数据，并在二元属性情况下规约为Jaccard系数</li>
</ul>
</li>
</ol>
<img src="../../../Pictures/image-20250310212143846.png" alt="image-20250310212143846" style="zoom:40%;" />

<ol start="4">
<li>相关性<ul>
<li>皮尔逊相关系数是衡量两个变量之间线性关联程度 的一个度量，通常用于度量两个数据集之间的关系</li>
</ul>
</li>
</ol>
<img src="../../../Pictures/image-20250310212440456.png" alt="image-20250310212440456" style="zoom:40%;" />

<img src="../../../Pictures/image-20250310212501150.png" alt="image-20250310212501150" style="zoom:40%;" />

<p>Bregman散度</p>
<h3 id="2-4-6-邻近度计算问题"><a href="#2-4-6-邻近度计算问题" class="headerlink" title="2.4.6 邻近度计算问题"></a>2.4.6 邻近度计算问题</h3><ol>
<li>距离度量的标准化和相关性</li>
<li>组合异种属性的相似度</li>
<li>使用权重</li>
</ol>
<h3 id="2-4-7-选择正确的邻近性度量"><a href="#2-4-7-选择正确的邻近性度量" class="headerlink" title="2.4.7 选择正确的邻近性度量"></a>2.4.7 选择正确的邻近性度量</h3><ul>
<li>稠密、连续的数据，通常使用距离度量，如<strong>欧几里得距离</strong></li>
<li>稀疏（大部分对象都只具有少量被属性描述的性质）、非对称的数据，使用<strong>余弦、Jaccard和广义Jaccard度量</strong></li>
<li>时间序列的量值是重要的，<strong>欧几里得距离</strong></li>
<li>时间序列代表不同的量（比如：血压和氧消耗量），通常需要时间序列是否具有相同的性质，而不是相同的量值：<strong>相关度</strong></li>
</ul>
<h1 id="第三章-exploring-data"><a href="#第三章-exploring-data" class="headerlink" title="第三章 exploring data"></a>第三章 exploring data</h1><ol>
<li>data warehouse<ul>
<li>决策数据库（存储的不是实时数据，而是整理统计之后的数据），与其相对应的是组织的操作数据库</li>
<li>性质<ul>
<li>subject-oriented: 提供围绕主题（比如“客户”“产品”“销售”）、只与决策相关的数据，而不是基于日常操作流程或事务性处理</li>
<li>integrated：整合多个异构数据源（关系型数据库、平面文件、在线交易记录等）来构建。应用数据清洗和数据集成技术，确保不同数据源之间的一致性，包括命名约定、编码结构、属性度量等。</li>
<li>time-variant：数据仓库的数据时间跨度远远大于操作系统的时间跨度。区分一个概念：operational database(当前的value data，operation data而且可能没有时间元素), data warehouse data: 历史很长时间提供的信息</li>
<li>non-volatile: 数据仓库中的数据一旦被加载进入仓库，就不再进行频繁的更新或删除。数据仓库存储的是经过整合和转换后的历史数据，主要用于分析和决策支持</li>
</ul>
</li>
<li>Data Warehouse vs. Heterogeneous DBMS(异构数据库管理系统)<ul>
<li>Traditional heterogeneous DB integration<ul>
<li>在异构数据库(heterogeneous)库上构建wrappers&#x2F;mediators(包装器&#x2F;中介)</li>
<li>query driven approach:每次你想查询数据时，系统需要先转换问题，去不同的地方取数据，再合并。这个过程有点像在找不同的地方查资料，效率可能会比较低。各个地方还会为了查询竞争资源</li>
</ul>
</li>
<li>data warehouse: update-driven（更新驱动）【不是实时更新的，一段时间汇集数据进行分析】，性能很好<ul>
<li>数据已经提前整理好并存储在一个地方，你查询时可以非常快速、直接地拿到想要的数据，不需要再做额外的处理。</li>
</ul>
</li>
</ul>
</li>
<li>Data Warehouse vs. Operational DBMS<ul>
<li>OLTP (on-line transaction processing)——操作数据库<ul>
<li>传统 relational DBMS: day-to-day operations</li>
</ul>
</li>
<li>OLAP (on-line analytical processing)——数据仓库<ul>
<li>data warehouse system的主要任务，用于数据分析和决策</li>
</ul>
</li>
<li>Distinct features (OLTP vs. OLAP)<ul>
<li>User and system orientation: customer vs. market</li>
<li>Data contents: current, detailed vs. historical, consolidated</li>
<li>Database design: ER + application vs. star + subject</li>
<li>View: current, local vs. evolutionary, integrated</li>
<li>Access patterns: update vs. read-only but complex queries</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>data warehousing: 构建和使用数据仓库的过程</li>
</ol>
<h1 id="K-means-Clustering"><a href="#K-means-Clustering" class="headerlink" title="K-means Clustering"></a>K-means Clustering</h1><ol>
<li><p>什么不是聚类</p>
<ul>
<li>简单的分割</li>
<li></li>
</ul>
</li>
<li><p>Types of clusters</p>
<ul>
<li>Density-Based</li>
<li>objective function</li>
</ul>
</li>
<li><p>Solutions to Initial Centroids Problem</p>
<ul>
<li>初始中心点选择影响大，有几种解决方案<ul>
<li>多次运行：每次使用不同的随机初始中心点，之后选择最优的聚类结果（通常依据聚类误差或者其他指标），这种方法增加了计算成本，但是减少了局部最优问题</li>
<li>Sample and Use Hierarchical Clustering to Determine Initial Centroids：先使用**层次聚类（Hierarchical Clustering）**对数据进行初步聚类，然后将这些簇的中心作为 K-means 的初始中心点</li>
<li>远离已有中心点的方法（Farthest Point Selection）<ul>
<li>随机选择一个点&#x2F;选取所有点的质心点</li>
<li>每次选择距离<strong>当前已有中心点最远</strong>的点作为新的初始中心点</li>
</ul>
</li>
<li>postprocessing: 合并小簇，如果某些簇的样本数过少，将其合并到最近的簇</li>
<li>使用K-means变体，bisecting K-means<ul>
<li>先将所有数据视为一个大簇，计算其中心点。</li>
<li>然后，对该簇执行两次 K-means（K&#x3D;2），分裂为两个子簇。</li>
<li>继续对其中误差较大的簇再次执行二分，直到达到预定的簇数。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Limitations of K-means</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/03/09/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" data-id="cm81snc5h0001gcdp4jwp8ku5" data-title="数据挖掘" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-CLIP" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/03/09/CLIP/" class="article-date">
  <time class="dt-published" datetime="2025-03-09T06:21:28.000Z" itemprop="datePublished">2025-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/03/09/CLIP/">CLIP</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Learning-Transferable-Visual-Models-From-Natural-Language-Supervision"><a href="#Learning-Transferable-Visual-Models-From-Natural-Language-Supervision" class="headerlink" title="Learning Transferable Visual Models From Natural Language Supervision"></a>Learning Transferable Visual Models From Natural Language Supervision</h1><p>利用自然语言的监督信号去学习迁移好的视觉模型</p>
<hr>
<p>ClIP迁移学习能力能力非常强，可以在任意一个视觉分类的数据集上，取得不错的效果，而且是zero-shot【没有在这些数据集上做训练就可以获得很高的效果】</p>
<p>之前最先进的视觉系统训练都是先有一个固定的提前已经定义好的物体类别（ImageNet就有固定1000个类，CIFAR10就有10个类，coco就是80个类）的集合，之后模型通过去预测这些提前定义好的类别从而完成模型的训练</p>
<p><img src="/../../../Pictures/image-20250309145138600.png" alt="image-20250309145138600"></p>
<ul>
<li>图片经过image encoder获得一些特征，这里的图片编码器可以是resnet &#x2F; ViT</li>
<li>文字通过text encoder获得文字特征</li>
<li>CLIP接着在这些特征上做对比学习，特征矩阵里对角线方向都是正样本，即有n个正样本，$n^2-n$个负样本, 有了正负样本，模型就可以自己训练而不需要手工标注，属于无监督的预训练方式，需要大量数据</li>
<li>对比学习<ul>
<li>只需要正样本和负样本的定义</li>
</ul>
</li>
</ul>
<p><img src="/../../../Pictures/image-20250309145832474.png" alt="image-20250309145832474"></p>
<ul>
<li>CLIP做zero-shot推理<ul>
<li>CLIP模型预训练之后只能得到视觉和文本特征，没有在分类任务上继续做训练和微调，没有分类头，所以使用prompt templte（自然语言的方法）进行推理<ul>
<li>先把image_net里面1000个类变成一个句子，之后通过text encoder得到1000个文本特征<ul>
<li>为什么要将单词变成句子，因为训练的时候是句子，现在突然变成单词，效果会下降</li>
<li>如何变成句子也很讲究，所以之后也提出了prompt engineering和prompt ensemble两种方式进一步提高模型准确率，而不需要重新训练模型</li>
</ul>
</li>
<li>获得一张图片，放进image encoder获得图片特征，将这一个图片特征和1000个文本特征做cosine similarity，之后图像特征和哪个文本特征最相似，就把文本特征所对应的那个句子挑出来，从而完成分类</li>
</ul>
</li>
<li>彻底摆脱categorical label,不管训练还是推理都不要一个提前订好的标签的列表，任意一张照片，都可以给模型喂不同的文本句子，从而指导图片里又是没有感兴趣的物体，CLIP因为和自然语言处理的结合，CLIP学出的视觉特征和用语言描述的某个物体产生强烈的联系</li>
</ul>
</li>
<li>应用<ul>
<li>分类</li>
<li>图像生成<ul>
<li>StyleCLIP</li>
<li>CLIPDraw(不需要模型训练，只需要几步gradient descent就可以生成简笔画)</li>
</ul>
</li>
<li>物体检测和分割<ul>
<li>Open-vocabulary object detection via vision and language knowledge distillation(google)</li>
<li>clifs(视频检索)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>自监督方式：自回归预测的方式还是掩码完形填空</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/03/09/CLIP/" data-id="cm81snc5k0003gcdpd41bc2p4" data-title="CLIP" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-CLIP-Adapter" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/03/09/CLIP-Adapter/" class="article-date">
  <time class="dt-published" datetime="2025-03-09T06:18:15.000Z" itemprop="datePublished">2025-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/03/09/CLIP-Adapter/">CLIP-Adapter</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/03/09/CLIP-Adapter/" data-id="cm81snc570000gcdpba1ghsfz" data-title="CLIP-Adapter" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-多模态-llava基础知识" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/03/09/%E5%A4%9A%E6%A8%A1%E6%80%81-llava%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="article-date">
  <time class="dt-published" datetime="2025-03-08T16:01:33.000Z" itemprop="datePublished">2025-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/03/09/%E5%A4%9A%E6%A8%A1%E6%80%81-llava%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">多模态/llava基础知识</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="llava-large-language-and-vision-assistant"><a href="#llava-large-language-and-vision-assistant" class="headerlink" title="llava(large language and vision assistant)"></a>llava(large language and vision assistant)</h1><h2 id="架构介绍"><a href="#架构介绍" class="headerlink" title="架构介绍"></a>架构介绍</h2><p><img src="/../images/llava.png" alt="图片1"></p>
<p>llava模型由3个部分组成，视觉编码器，一个简单的线性层和大语言模型。</p>
<p>$X_q$大预言指令被编码成$H_q$, $X_v$图像经过视觉编码器编码成$Z_v$，之后经过投影矩阵W获得$H_v$，最终$H_v$和$H_q$相同维度，之后经过大预言模型给出response</p>
<p>原论文架构：</p>
<ul>
<li><p>vision encoder：使用pre-trained CLIP的visual encoder ViT-L&#x2F;14，得到visual feature($Z_v$)&#x3D;g($X_v$)</p>
</li>
<li><p>projection W:一个简单的线性层，使用可训练的投影矩阵W，将视觉特征Z_v投影成language embedding tokens$H_v$（visual tokens），使得$H_v$和文本特征$H_q$在同一特征维度；也可以使用更加复杂的比如gated cross-attention in Flamingo和Q-former in BILP-2来代替</p>
<ul>
<li>图像通过投影层映射到与文本特征相同的空间之后，直接进入Transformer的最后一层，实现图像特征和文本特征的有效融合</li>
</ul>
</li>
<li><p>language model: 生成word embedding, 给出回答，原论文中使用vicuna（因为它在大语言任务拥有最好的instruction following capabilities）</p>
</li>
</ul>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><ol>
<li><p>对于每个图像$X_v$生成多轮对话数据，每轮对话有两个部分：问题($X_q$)和答案($X_a$)</p>
</li>
<li><p>将所有的对话都按照顺序组成一个整体序列，问题回答交替组织，每一轮随机选择图片和问题的顺序</p>
<p><img src="/../images/format.png" alt="图片2"></p>
</li>
<li><p>通过自回归的方法逐步生成每一个回答，对于每一个生成的回答，使用$p(Xa|Xv, Xinstr) &#x3D;  \prod_ {i&#x3D;1}^Lp_θ(xi|Xv, X_{instr},&lt;i, Xa,&lt;i)$</p>
<ul>
<li>$X_a$是目标答案，所以这个是寻找目标答案的概率</li>
</ul>
</li>
<li><p>训练细节，训练时只有绿色标记（assistant的回答）会用来计算损失，最终训练目标不仅要预测助手的回答，还要学习生成一个停止标记<STOP>结束对话</p>
</li>
<li><p>两阶段指令微调(训练)</p>
<ul>
<li>第一阶段：pre-training for feature alignment【主要目标是将图像特征和语言模型的词嵌入对齐，构造兼容视觉标记器】<ul>
<li>数据筛选：从CC3M数据集(包含大量图像-文本对的大型数据集)中筛选出595K对图像和文本</li>
<li>将图像-文本对转化为指令跟随数据，每个图像都有一个简单的指令配对</li>
<li>冻结视觉编码器和LLM权重，只有投影矩阵W进行训练，投影矩阵作用是将图像特征与语言模型的词嵌入对齐，使得视觉信息和语言信息在训练过程中相互关联</li>
</ul>
</li>
<li>第二阶段：Fine-tuning End-to-End<ul>
<li>视觉编码器权重依然被冻结，投影层和LLM权重被微调</li>
<li>考虑两个具体的应用场景<ul>
<li>多模态聊天机器人</li>
<li>science QA</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/03/09/%E5%A4%9A%E6%A8%A1%E6%80%81-llava%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" data-id="cm81snc5j0002gcdp9ra3gklf" data-title="多模态/llava基础知识" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/08/">August 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/08/01/Github%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/08/01/ViT%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/23/leecode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/03/12/AutoDL%E4%BD%BF%E7%94%A8/">AutoDL使用</a>
          </li>
        
          <li>
            <a href="/2025/03/11/CoHD/">CoHD</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>